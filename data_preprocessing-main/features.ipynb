{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature generation\n",
    "This repository contains the code for generating the different kinds of features for traditional machine learning for the Capstone project.\n",
    "\n",
    "### Instructions\n",
    "1. compile the functions (cv2 lib has to be installed)\n",
    "2. arguements: image - the target image for calculating the features, length nice to be equal to width\n",
    "3. set arguements of each function (There are tons of parameters can be adjusted, please refer to the reference link)\n",
    "4. run functions and collect the return feature\n",
    "4. returns are in numpy array format\n",
    "\n",
    "### Reference\n",
    "1. numpy array: https://numpy.org/doc/stable/reference/arrays.html\n",
    "2. sample and definition of HoG: https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html\n",
    "3. edge detection: https://docs.opencv.org/3.4/da/d22/tutorial_py_canny.html\n",
    "4. CV2 of Python (openCV): https://pypi.org/project/opencv-python/\n",
    "5. local binary pattern histogram: https://pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ePL-bjmn0thW"
   },
   "outputs": [],
   "source": [
    "#data feature\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.measure import regionprops\n",
    "from skimage.morphology import binary_erosion\n",
    "from scipy.special import comb\n",
    "import numpy.fft as fft\n",
    "\n",
    "\n",
    "# get horitonzal edges from sobelY\n",
    "def number_of_edgePixels(image):\n",
    "    sobelY = cv2.Sobel(image, cv2.CV_64F,0,1,ksize=5)\n",
    "    return np.count_nonzero(sobelY==255)\n",
    "\n",
    "# std of mean of rows, get high value for black/white horisontal stripes.\n",
    "def std_meanOfRows(image):\n",
    "    mean_row = np.mean(image, axis=1)\n",
    "    return np.std(mean_row, dtype=np.float32)\n",
    "\n",
    "# Computes the Laplacian of the image and returns the mean value of all the pixels. \n",
    "# A higher value indicates more edges and details in the image\n",
    "def mean_laplacian(image):\n",
    "    return cv2.mean(cv2.Laplacian(image, cv2.CV_64F))[0]\n",
    "\n",
    "# mean number of peak and valleys in each column, get high value for noisy pictures.\n",
    "def mean_PeaksValleys(image):\n",
    "    peaks_valleys = []\n",
    "    for j in range(image.shape[1]):\n",
    "        col = image[:, j]\n",
    "        num_peaks, num_valleys = count_peaks_valleys(col)\n",
    "        mean_peaks_valleys = (num_peaks + num_valleys) / 2\n",
    "        peaks_valleys.append(mean_peaks_valleys)\n",
    "    return np.mean(peaks_valleys, dtype=np.float32)\n",
    "    \n",
    "def count_peaks_valleys(arr_1d):\n",
    "    num_peaks = 0\n",
    "    num_valleys = 0\n",
    "    for i in range(1, len(arr_1d) - 1):\n",
    "        if arr_1d[i] > arr_1d[i-1] and arr_1d[i] > arr_1d[i+1]:\n",
    "            num_peaks += 1\n",
    "        elif arr_1d[i] < arr_1d[i-1] and arr_1d[i] < arr_1d[i+1]:\n",
    "            num_valleys += 1\n",
    "    return (num_peaks, num_valleys)\n",
    "\n",
    "# numbers of edges from canny edge detection, use dfs to explore number of group of edge pixels\n",
    "def num_edges_canny(image, L2Gradient, sobel_kernal_size):\n",
    "    T_lower = 100\n",
    "    T_upper = 200 \n",
    "    edge = cv2.Canny(image, T_lower, T_upper, apertureSize=sobel_kernal_size, L2Gradient = L2Gradient)\n",
    "    def dfs(r, c):\n",
    "        if r < 0 or r >= np.size(image, 0) or c < 0 or c >= np.size(image, 1) or image[r][c] == 0:\n",
    "            return 0\n",
    "            \n",
    "        image[r][c] = 0\n",
    "            \n",
    "        for i, j in zip((r - 1, r + 1, r, r), (c, c, c - 1, c + 1)):\n",
    "            dfs(i, j)\n",
    "            \n",
    "        return 1\n",
    "    \n",
    "    return sum(dfs(i, j) for i in range(np.size(image, 0)) for j in range(np.size(image, 1)))\n",
    "\n",
    "def lbp_histogram(image, radius, bins):\n",
    "    # compute the LBP histogram of the image\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(image, n_points, radius, method='uniform')\n",
    "    hist, _ = np.histogram(lbp, bins= bins, density=True)\n",
    "    return np.ravel(hist)\n",
    "\n",
    "# Haralick features \n",
    "# describe the texture of an image by computing statistics from the gray-level co-occurrence matrix (GLCM) of the image.\n",
    "def haralick_contrast(image, distance=1, angle=0):\n",
    "    glcm = graycomatrix(image, [distance], [angle], levels=256, symmetric=True, normed=True)\n",
    "    return graycoprops(glcm, 'contrast')[0, 0]\n",
    "\n",
    "#Hu moments are a set of shape features that are invariant to rotation, scale, and translation. \n",
    "# They can be computed from the moments of an image's contour\n",
    "def hu_moments(image):\n",
    "    moments = cv2.moments(image)\n",
    "    hu_moments = cv2.HuMoments(moments)\n",
    "    return np.ravel(hu_moments)\n",
    "\n",
    "#set of shape features that are invariant to rotation, scale, and translation. \n",
    "# They can be computed from the radial and angular moments of an image's contour\n",
    "def zernike_moments(image, radius=1, degree=8):\n",
    "    eroded_image = binary_erosion(image, np.ones((2*radius+1, 2*radius+1)))\n",
    "    props = regionprops(eroded_image.astype(np.uint8))\n",
    "    moments = np.zeros(degree+1)\n",
    "    for prop in props:\n",
    "        r = np.sqrt(prop.area/np.pi)\n",
    "        if r < radius:\n",
    "            z = np.complex(prop.centroid[1], prop.centroid[0])\n",
    "            for n in range(degree+1):\n",
    "                for m in range(-n, n+1, 2):\n",
    "                    if m < 0:\n",
    "                        cmn = comb(n, int((n-m)/2))\n",
    "                        fm = np.exp(np.complex(0, m*prop.orientation))\n",
    "                        moments[n] += (r**n) * cmn\n",
    "\n",
    "#GLCM-based texture features\n",
    "def glcm_features(image):\n",
    "    # Compute the gray-level co-occurrence matrix\n",
    "    glcm = graycomatrix(image, [5], [0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
    "    \n",
    "    # Compute some commonly used GLCM features\n",
    "    contrast = graycoprops(glcm, 'contrast')\n",
    "    dissimilarity = graycoprops(glcm, 'dissimilarity')\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity')\n",
    "    energy = graycoprops(glcm, 'energy')\n",
    "    correlation = graycoprops(glcm, 'correlation')\n",
    "    \n",
    "    # Concatenate the features into a single vector\n",
    "    features = np.concatenate([contrast, dissimilarity, homogeneity, energy, correlation])\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "# Fourier descriptors represent the shape of an object in terms of its frequency components\n",
    "def fourier_shape_features(image):\n",
    "    # Compute the Fourier Transform of the image\n",
    "    f = fft.fft2(image)\n",
    "    \n",
    "    # Shift the zero frequency component to the center\n",
    "    fshift = fft.fftshift(f)\n",
    "    \n",
    "    # Take the magnitude of the Fourier Transform\n",
    "    magnitude_spectrum = np.log(np.abs(fshift))\n",
    "    \n",
    "    # Extract the Fourier coefficients for the first 5 frequencies in each dimension\n",
    "    n = image.shape[0]\n",
    "    m = image.shape[1]\n",
    "    p = 5\n",
    "    descriptors = np.zeros((p, p))\n",
    "    for i in range(p):\n",
    "        for j in range(p):\n",
    "            descriptors[i, j] = np.abs(fshift[n//2 + i, m//2 + j])\n",
    "    \n",
    "    # Flatten the descriptors into a single vector\n",
    "    features = descriptors.flatten()\n",
    "    return np.ravel(features)\n",
    "\n",
    "# HoG\n",
    "def hog_(image, image_size):\n",
    "    gray_img = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140])\n",
    "    fd, hog_image = hog(image, orientations=9, pixels_per_cell=(100, 100),\n",
    "                \tcells_per_block=(2, 2), visualize=True, feature_vector = True)\n",
    "#     print(fd.shape)\n",
    "#     print(hog_image.shape)\n",
    "    return fd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZqayDRD3Rht",
    "outputId": "b8237208-9a8d-4a51-d50c-26728fbdb3dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2910, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.utils import Bunch\n",
    "npdata = np.load('/content/2910_datasetC_200x200.npz')\n",
    "print(npdata['data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aqezqG1X02hn"
   },
   "outputs": [],
   "source": [
    "#example of using features to train model\n",
    "number_image = 2910\n",
    "feature = 9\n",
    "img=np.zeros(shape=(number_image,feature))\n",
    "for i in range(0,number_image): \n",
    "    img[i][0] = number_of_edgePixels(npdata['data'][i])\n",
    "    img[i][1] = std_meanOfRows(npdata['data'][i])\n",
    "    img[i][2] = mean_PeaksValleys(npdata['data'][i])\n",
    "    img[i][3] = np.std(npdata['data'][i])\n",
    "    img[i][4] = mean_laplacian(npdata['data'][i])\n",
    "    img[i][5] = hu_moments(npdata['data'][i])[0]\n",
    "    img[i][6] = zernike_moments(npdata['data'][i])\n",
    "    img[i][7] = glcm_features(npdata['data'][i])[0][0]\n",
    "    img[i][8] = fourier_shape_features(npdata['data'][i])[0]\n",
    "    \n",
    "print(img.shape)\n",
    "dataset = Bunch(data = img, target=npdata['label'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
