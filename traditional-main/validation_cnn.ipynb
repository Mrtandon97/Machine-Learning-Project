{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation CNN Model\n",
    "The CNN model is validated using the test dataset.  \n",
    "The validation is similar to data pipeline. The difference is that the validation will compare the output of the model with the annotations of the test dataset.  \n",
    "Beside the model itself, the performance of the model also depends on the resize ratio and the threshold of the voting.\n",
    "\n",
    "## Output\n",
    "The output of the validation is a image with the output of the model.\n",
    "The true positives are marked in green, the false positives in red. There is a blue line in the video to simulate the position of the GPR instrument. The output files include:\n",
    "- `validation_CNN.jpg`: The GPR image same as the input image, but with the label generated by the model.\n",
    "- `validation_CNN.mp4`: The video recording the labeling process with the size of original image.\n",
    "- `moving_validation_CNN.mp4`: The video recording the labeling process with fixed size of the frame that is 16:9.\n",
    "\n",
    "## Metrics\n",
    "The metrics used to validate the model are:\n",
    "- Recall\n",
    "- Area Precision\n",
    "\n",
    "A true positive is a prediction that lies within the range of the hyperbola in annotation. A false positive is a prediction that does not lie within the range of the hyperbola in annotation.  \n",
    "Recall is calculated as the number of detected hyperbolas divided by the total number of hyperbolas in the image. A detected hyperbola means a true positive prediction lies within the range of the hyperbola in annotation.  \n",
    "Area precision is calculated as the number of true positives divided by the number of true positives plus the number of false positives.\n",
    "\n",
    "## Recording\n",
    "There are two function to record the validation.\n",
    "- `validate_label_video` records the validation with the size of original image.\n",
    "- `moving_window_video` records the validation with fixed size of the frame that is 16:9.\n",
    "\n",
    "If the width of the original image is larger than 2000 pixels, the `moving_window_video` function is recommended.  \n",
    "If the width of the original image too small to maintain the aspect ratio of 16:9, the `validate_label_video` function is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import cv2\n",
    "import joblib\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow import keras\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for parsing CVAT annotations\n",
    "def image_names_parser(path):\n",
    "    tree = ET.parse(f'{path}/annotations.xml')\n",
    "    root = tree.getroot()\n",
    "    image_names = []\n",
    "    for image in root.findall('image'):\n",
    "        image_names.append(image.get('name'))\n",
    "    return image_names\n",
    "\n",
    "def labels_parser(path, image_name):\n",
    "    tree = ET.parse(f'{path}/annotations.xml')\n",
    "    root = tree.getroot()\n",
    "\n",
    "    labels = {}\n",
    "    for i, label in enumerate(root.iter('label')):\n",
    "        labels[label.find('name').text] = i\n",
    "\n",
    "    image_node = None\n",
    "    for image in root.findall('image'):\n",
    "        if image.get('name') == image_name:\n",
    "            image_node = image\n",
    "\n",
    "    boxs = []\n",
    "    coordinates = ['ytl', 'xtl', 'ybr', 'xbr']\n",
    "    for i in range(len(labels)):\n",
    "        boxs.append([])\n",
    "    for box in image_node.findall('box'):\n",
    "        points = []\n",
    "        for coordinate in coordinates:\n",
    "            points.append(int(box.get(coordinate).split(\".\")[0]))\n",
    "        boxs[labels[box.get('label')]].append(points)\n",
    "\n",
    "    return boxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_out_of_box(sliding_window, box):\n",
    "    if sliding_window[2] < box[0] or sliding_window[0] > box[2]:\n",
    "        return True\n",
    "    if sliding_window[3] < box[1] or sliding_window[1] > box[3]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def check_box(sliding_window, box, overlapping):\n",
    "    if check_out_of_box(sliding_window, box):\n",
    "        return False\n",
    "    \n",
    "    box_area = (box[2] - box[0]) * (box[3] - box[1])\n",
    "    overlap_area = (min(sliding_window[2], box[2]) - max(sliding_window[0], box[0])) * (min(sliding_window[3], box[3]) - max(sliding_window[1], box[1]))\n",
    "    if overlap_area / box_area < overlapping:\n",
    "        return False    \n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the voting result based on the index of the sliding window\n",
    "def label_voting(validate_result, threshold, image_shape, sliding_window_size, step, image_start):\n",
    "    height = math.ceil((image_shape[0] - sliding_window_size - image_start[0]) / step)\n",
    "    width = math.ceil((image_shape[1] - sliding_window_size - image_start[1]) / step)\n",
    "    voting = np.zeros((height + 4, width + 4))\n",
    "    total = np.zeros((height + 4, width + 4))\n",
    "\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            p = validate_result[i + j * width, 1]\n",
    "            voting[j : j + 5, i : i + 5] += np.ones((5, 5)) * p\n",
    "            total[j : j + 5, i : i + 5] += np.ones((5, 5))\n",
    "    voting /= total\n",
    "    voting = np.where(voting > threshold, 1, 0)\n",
    "    return voting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 200, 200, 32)      832       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 200, 200, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 100, 100, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 100, 100, 64)      51264     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 100, 100, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 50, 50, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 50, 50, 128)       204928    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 50, 50, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 25, 25, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 25, 25, 256)       819456    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 25, 25, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 12, 12, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 36864)             0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 36864)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2048)              75499520  \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 76,580,098\n",
      "Trainable params: 76,580,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = \"saved_models/hyperbola_vgg2.keras\"\n",
    "model = keras.models.load_model(model_name, compile = False)\n",
    "model.compile()\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Setting\n",
    "The parameters of the validation are:\n",
    "- `IMAGE_START`, `AXIS_ZERO`:ã€€The start position of the image containing signal from the surface.\n",
    "- `image_name`: The name of the GPR image.\n",
    "- `label_path`: The path of the annotation.\n",
    "- `scale_percent`: The resize ratio of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# IMAGE_START excludes the left axis of the image.\n",
    "# AXIS_ZERO excludes the top axis of the image. For 1st dataset and 2nd dataset, this also excludes\n",
    "# the first few nano seconds of the image that receive no signal from the surface.\n",
    "\n",
    "# Boundary constant of images\n",
    "IMAGE_START = 64\n",
    "AXIS_ZERO = 44     # 1st dataset, 2nd dataset: 121, 3rd dataset: 44\n",
    "\n",
    "image_name = \"ARR7_350_230324__001 P_31111111.JPG\"\n",
    "image_path = f\"../data_preprocessing/unprocessed_images/{image_name}\"\n",
    "# label_path = '../data_preprocessing/annotations/1stdataset20230420' # 1st dataset\n",
    "# label_path = '../data_preprocessing/annotations/2ndDataset20230421' # 2nd dataset\n",
    "label_path = '../data_preprocessing/annotations/3rdDataset20230420' # 3rd dataset\n",
    "labels = labels_parser(label_path, image_name.replace('.JPG', '_processed.JPG'))\n",
    "\n",
    "sliding_window_size = 200\n",
    "step = 40\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# scale down\n",
    "scale_percent = 100 # percent of original size\n",
    "width = int(img.shape[1] * scale_percent / 100)\n",
    "height = int(img.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "  \n",
    "# resize image\n",
    "img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "IMAGE_START = int(IMAGE_START * scale_percent / 100)\n",
    "AXIS_ZERO = int(AXIS_ZERO * scale_percent / 100)\n",
    "image_start = [AXIS_ZERO, IMAGE_START]\n",
    "\n",
    "height = math.ceil((img.shape[0] - sliding_window_size - image_start[0]) / step)\n",
    "width = math.ceil((img.shape[1] - sliding_window_size - image_start[1]) / step)\n",
    "number_image = height * width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_label(image, labels, voting, scale_percent, image_name, file_name='output.jpg'):\n",
    "    img = copy.deepcopy(image)\n",
    "\n",
    "    print(f'evaluating {image_name}...')\n",
    "    feature_types = ['small strong hyperbola', 'small weak hyperbola', 'noise', 'large strong hyperbola', 'large weak hyberbola', 'no feature']\n",
    "    image_shape = img.shape\n",
    "    height = math.ceil((image_shape[0] - sliding_window_size - image_start[0]) / step)\n",
    "    width = math.ceil((image_shape[1] - sliding_window_size - image_start[1]) / step)\n",
    "\n",
    "    print(voting.shape)\n",
    "    no_feature_index = len(feature_types) - 1\n",
    "    label_check = np.zeros(len(feature_types))\n",
    "    total_label = 0\n",
    "    \n",
    "    hyperbola_feature = [0, 1, 3, 4]\n",
    "    for k in hyperbola_feature:\n",
    "        for box in labels[k]:\n",
    "            box_index = []\n",
    "            # transform the image coordinates to the index of the sliding window\n",
    "            for i, b in enumerate(box):\n",
    "                if i % 2 == 0:\n",
    "                    box_index.append((b * scale_percent / 100 - image_start[0]) / step)\n",
    "                else:\n",
    "                    box_index.append((b * scale_percent / 100 - image_start[1]) / step)\n",
    "            start = [math.floor(box_index[0]), math.floor(box_index[1])]\n",
    "            end = [math.ceil(box_index[2] + 1), math.ceil(box_index[3] + 1)]\n",
    "            is_feature = False\n",
    "            for j in range(max(start[0], 0), min(end[0] + 4, height)):\n",
    "                for i in range(max(start[1], 0), min(end[1] + 4, width)):\n",
    "                    # voting[j, i] = 1 if false positive, 2 if true positive\n",
    "                    if voting[j, i] == 1 and not check_out_of_box([j, i, j + 1, i + 1], box_index):\n",
    "                        voting[j, i] = 2\n",
    "                        is_feature = True\n",
    "            if is_feature:\n",
    "                label_check[k] += 1\n",
    "\n",
    "        print(f'{feature_types[k]} recall: {int(label_check[k])} / {len(labels[k])} ( {label_check[k] / len(labels[k]) * 100:.1f} % )')\n",
    "        total_label += len(labels[k])\n",
    "    print(f'overall recall: {int(sum(label_check))} / {total_label} ( {int(sum(label_check)) / total_label * 100:.1f} % )')\n",
    "\n",
    "    precision = 0\n",
    "    total = 0\n",
    "    for j in range(height + 4):\n",
    "        for i in range(width + 4):\n",
    "            if voting[j, i] > 0:\n",
    "                total += 1\n",
    "                if voting[j, i] == 2:\n",
    "                    precision += 1\n",
    "    if (total == 0):\n",
    "        print('area precision not available')\n",
    "    else:\n",
    "        print(f'area precision: {precision / total * 100:.1f} %')\n",
    "\n",
    "    box_width = 2\n",
    "    for j in range(height + 4):\n",
    "        for i in range(width + 4):\n",
    "            box = [image_start[1] + i * step, image_start[0] + j * step, image_start[1] + (i + 1) * step, image_start[0] + (j + 1) * step]\n",
    "            # label the box with different color. Red for false positive, and green for true positive.\n",
    "            if voting[j, i] == 1:\n",
    "                color = np.array([229, 0, 0]) # red\n",
    "            elif voting[j, i] == 2:\n",
    "                color = np.array([21, 176, 26]) # green\n",
    "\n",
    "            if voting[j, i] > 0:\n",
    "                img[box[1] - box_width:box[1] + box_width, box[0]:box[2], :] = np.ones_like(img[box[1] - box_width:box[1] + box_width, box[0]:box[2], :]) * color\n",
    "                img[box[3] - box_width:box[3] + box_width, box[0]:box[2], :] = np.ones_like(img[box[3] - box_width:box[3] + box_width, box[0]:box[2], :]) * color\n",
    "                img[box[1]:box[3], box[0] - box_width:box[0] + box_width, :] = np.ones_like(img[box[1]:box[3], box[0] - box_width:box[0] + box_width, :]) * color\n",
    "                img[box[1]:box[3], box[2] - box_width:box[2] + box_width, :] = np.ones_like(img[box[1]:box[3], box[2] - box_width:box[2] + box_width, :]) * color\n",
    "    plt.imshow(img)\n",
    "    plt.imsave(file_name, img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing\n",
    "Crop the image into 200 x 200 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12416, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "sub_images = np.zeros(shape=(number_image, 200, 200), dtype='float32')\n",
    "\n",
    "for j in range(height):\n",
    "    for i in range(width):\n",
    "        sliding_window = [image_start[0] + j * step, image_start[1] + i * step, image_start[0] + sliding_window_size + j * step, image_start[1] + sliding_window_size + i * step]\n",
    "        sub_img = img[sliding_window[0]:sliding_window[2], sliding_window[1]:sliding_window[3]]\n",
    "        rgb_weights = [0.2990, 0.5870, 0.1140]\n",
    "        sub_img = np.dot(sub_img[...,:3], rgb_weights)\n",
    "        sub_img = np.array(sub_img)\n",
    "\n",
    "        sub_images[count] = sub_img / 255\n",
    "        count += 1\n",
    "        \n",
    "print(sub_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 292s 752ms/step\n",
      "(12416, 2)\n"
     ]
    }
   ],
   "source": [
    "validate_result = model.predict(sub_images)\n",
    "print(validate_result.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation\n",
    "The performance of the model is evaluated by the metrics.  \n",
    "Set the threshold of the voting in `label_voting` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating ARR7_350_230324__001 P_31111111.JPG...\n",
      "(20, 780)\n",
      "small strong hyperbola recall: 10 / 24 ( 41.7 % )\n",
      "small weak hyperbola recall: 13 / 30 ( 43.3 % )\n",
      "large strong hyperbola recall: 5 / 6 ( 83.3 % )\n",
      "large weak hyberbola recall: 8 / 20 ( 40.0 % )\n",
      "overall recall: 36 / 80 ( 45.0 % )\n",
      "area precision: 38.5 %\n",
      "execution time: 315.22 seconds\n",
      "image size: (847, 31280)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "voting = label_voting(validate_result, 0.25, img.shape, sliding_window_size, step, [AXIS_ZERO, IMAGE_START])\n",
    "validate_label(img, labels, voting, scale_percent, image_name, file_name='validation_CNN.jpg')\n",
    "print(f'execution time: {time.time() - start_time:.2f} seconds')\n",
    "print(f'image size: {(img.shape[0], img.shape[1])}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording the labeling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_label_video(image, voting, file_name='output.mp4'):\n",
    "    img = copy.deepcopy(image)\n",
    "    print('recording video...')\n",
    "    image_shape = img.shape\n",
    "    height = math.ceil((image_shape[0] - sliding_window_size - image_start[0]) / step)\n",
    "    width = math.ceil((image_shape[1] - sliding_window_size - image_start[1]) / step)\n",
    "    # the video is 30 fps with and size of the image\n",
    "    video_writer = cv2.VideoWriter(file_name, cv2.VideoWriter_fourcc(*'MP4V'), 30, (image_shape[1], image_shape[0]))\n",
    "    voting_i = 0\n",
    "    box_width = 2\n",
    "    for i in range(image_start[1], image_shape[1], 5):\n",
    "        video_color = np.array([223, 67, 3]) # blue\n",
    "        img[:, i - 6:i - 3, :] = image[:, i - 6:i - 3, :]\n",
    "        img[:, i - 1:i + 2, :] = np.ones_like(img[:, i - 1:i + 2, :]) * video_color\n",
    "        if i > image_start[1] + (voting_i + 1) * step:\n",
    "            for voting_j in range(height + 4):\n",
    "                box = [image_start[1] + voting_i * step, image_start[0] + voting_j * step, image_start[1] + (voting_i + 1) * step, image_start[0] + (voting_j + 1) * step]\n",
    "                if voting[voting_j, voting_i] > 0:\n",
    "                    if voting[voting_j, voting_i] == 1:\n",
    "                        video_color = np.array([0, 0, 229]) # red\n",
    "                    elif voting[voting_j, voting_i] == 2:\n",
    "                        video_color = np.array([26, 176, 21]) # green\n",
    "\n",
    "                    img[box[1] - box_width:box[1] + box_width, box[0]:box[2], :] = np.ones_like(img[box[1] - box_width:box[1] + box_width, box[0]:box[2], :]) * video_color\n",
    "                    img[box[3] - box_width:box[3] + box_width, box[0]:box[2], :] = np.ones_like(img[box[3] - box_width:box[3] + box_width, box[0]:box[2], :]) * video_color\n",
    "                    img[box[1]:box[3], box[0] - box_width:box[0] + box_width, :] = np.ones_like(img[box[1]:box[3], box[0] - box_width:box[0] + box_width, :]) * video_color\n",
    "                    img[box[1]:box[3], box[2] - box_width:box[2] + box_width, :] = np.ones_like(img[box[1]:box[3], box[2] - box_width:box[2] + box_width, :]) * video_color\n",
    "            voting_i += 1\n",
    "        video_writer.write(img)\n",
    "\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('video saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording video...\n",
      "video saved\n"
     ]
    }
   ],
   "source": [
    "validate_label_video(img, voting, file_name='validation_CNN.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_window_video(image, voting, file_name='output.mp4'):\n",
    "    img = copy.deepcopy(image)\n",
    "    print('recording video...')\n",
    "    image_shape = img.shape\n",
    "    frame = [image_shape[0], int(image_shape[0] * 16 / 9)]\n",
    "    height = math.ceil((image_shape[0] - sliding_window_size - image_start[0]) / step)\n",
    "    # the video is 30 fps with and fixed size of the image (16:9)\n",
    "    video_writer = cv2.VideoWriter(file_name, cv2.VideoWriter_fourcc(*'MP4V'), 30, (frame[1], frame[0]))\n",
    "    voting_i = 0\n",
    "    box_width = 2\n",
    "    for i in range(image_start[1], image_shape[1], 10):\n",
    "        video_color = np.array([223, 67, 3]) # blue\n",
    "        img[:, i - 11:i - 8, :] = image[:, i - 11:i - 8, :]\n",
    "        img[:, i - 1:i + 2, :] = np.ones_like(img[:, i - 1:i + 2, :]) * video_color\n",
    "        if i > image_start[1] + (voting_i + 1) * step:\n",
    "            for voting_j in range(height + 4):\n",
    "                box = [image_start[1] + voting_i * step, image_start[0] + voting_j * step, image_start[1] + (voting_i + 1) * step, image_start[0] + (voting_j + 1) * step]\n",
    "                if voting[voting_j, voting_i] > 0:\n",
    "                    if voting[voting_j, voting_i] == 1:\n",
    "                        video_color = np.array([0, 0, 229]) # red\n",
    "                    elif voting[voting_j, voting_i] == 2:\n",
    "                        video_color = np.array([26, 176, 21]) # green\n",
    "\n",
    "                    img[box[1] - box_width:box[1] + box_width, box[0]:box[2], :] = np.ones_like(img[box[1] - box_width:box[1] + box_width, box[0]:box[2], :]) * video_color\n",
    "                    img[box[3] - box_width:box[3] + box_width, box[0]:box[2], :] = np.ones_like(img[box[3] - box_width:box[3] + box_width, box[0]:box[2], :]) * video_color\n",
    "                    img[box[1]:box[3], box[0] - box_width:box[0] + box_width, :] = np.ones_like(img[box[1]:box[3], box[0] - box_width:box[0] + box_width, :]) * video_color\n",
    "                    img[box[1]:box[3], box[2] - box_width:box[2] + box_width, :] = np.ones_like(img[box[1]:box[3], box[2] - box_width:box[2] + box_width, :]) * video_color\n",
    "            voting_i += 1\n",
    "        if i - int(frame[1] * 2 / 3) < 0:\n",
    "            video_writer.write(img[:, :frame[1], :])\n",
    "        elif i + int(frame[1] * 1 / 3) > image_shape[1]:\n",
    "            video_writer.write(img[:, image_shape[1] - frame[1]:image_shape[1], :])\n",
    "        else:\n",
    "            video_writer.write(img[:, i - int(frame[1] * 2 / 3):i + int(frame[1] * 1 / 3), :])\n",
    "\n",
    "    video_writer.release()\n",
    "    print('video saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording video...\n",
      "video saved\n"
     ]
    }
   ],
   "source": [
    "moving_window_video(img, voting, file_name='moving_validation_CNN.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
